{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for asking! To create a debit note, you can follow these steps:\n",
      "\n",
      "1. Go to the \"Debit Note\" menu in the SQL Accounting system.\n",
      "2. Click on the \"New DN\" button to create a new debit note.\n",
      "3. Enter the customer code and amount to be debited.\n",
      "4. Select the project type (document or detail) and enter the project name.\n",
      "5. Attach any supporting documents if necessary.\n",
      "6. Click \"Save\" to save the debit note.\n",
      "\n",
      "That's it! You have successfully created a debit note in SQL Accounting. If you have any questions or need further assistance, feel free to ask."
     ]
    }
   ],
   "source": [
    "from urllib.parse import quote \n",
    "from timeit import default_timer as timer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "t1_start = timer()\n",
    "# Initialize embedding\n",
    "embedding = HuggingFaceEmbeddings(cache_folder=\"./modal\")\n",
    "# Initialize chroma persistentClient\n",
    "db = Chroma(collection_name=\"sql-wiki\", embedding_function=embedding, persist_directory=\"./chroma\")\n",
    "t1_end = timer()\n",
    "\n",
    "# Similarity search\n",
    "# qt_start = timer()\n",
    "# query = \"How do I fix backup error?\"\n",
    "# # query = \"How to create new debit note?\"\n",
    "# # query = \"How to import from autocount?\"\n",
    "# # result = db.similarity_search(query)\n",
    "# # Return 5 result with score more than 0.8\n",
    "# # result = db.similarity_search_with_relevance_scores(query=query, k=5, kwargs={\"score_threshold\": 0.8})\n",
    "# result = db.similarity_search_with_relevance_scores(query=query, k=1, kwargs={\"score_threshold\": 0.8})\n",
    "# qt_end = timer()\n",
    "\n",
    "# print(\"====================================================\")\n",
    "# print(\"Result: \")\n",
    "# print(len(result))\n",
    "# for r in result: \n",
    "#     print(r)\n",
    "#     print(r[0].metadata)\n",
    "#     print(\"https://wiki.sql.com.my/wiki/\"+quote(r[0].metadata[\"source\"]))\n",
    "# print(\"====================================================\")\n",
    "# print(\"Time: \")\n",
    "# print(\"Initialize time(s): \", round(t1_end - t1_start, 2))\n",
    "# print(\"Query time(s): %.2f\" % round(qt_end - qt_start, 2))\n",
    "\n",
    "\n",
    "\n",
    "# Define vector store db as retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # similarity, mmr\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# Define llm\n",
    "callback = StreamingStdOutCallbackHandler()\n",
    "llm = Ollama(model=\"llama2\", base_url=\"http://host.docker.internal:11434\", timeout=3000, temperature=0, callbacks=[callback])\n",
    "\n",
    "# Define prompt template for llm\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Helpful Answer: \"\"\"\n",
    "custom_prompt = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# RetrievalQA (use RetrievalQAWithSourcesChain to retrieve relevant data)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\", return_source_documents=True, chain_type_kwargs={\"prompt\": custom_prompt})\n",
    "# qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\", return_source_documents=True, chain_type_kwargs={\"prompt\": custom_prompt})\n",
    "\n",
    "result = qa_chain.invoke({\"query\": \"How to create a debit note?\"})\n",
    "# result = qa_chain({\"question\": \"How to create a debit note?\", \"context\": \"\"})\n",
    "# for chunk in result[\"result\"]:\n",
    "#     print(chunk)\n",
    "\n",
    "# print(result[\"source_documents\"])\n",
    "# print(result)\n",
    "# for d in result[\"source_documents\"]:\n",
    "#     print(d.metadata)\n",
    "#     print(\"https://wiki.sql.com.my/wiki/\"+quote(d.metadata[\"source\"]))\n",
    "\n",
    "# print(result)\n",
    "# print(result[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
